动机：解决什么问题
解决方案：创新点，什么架构，什么方法

# Extracting Motion and Appearance via Inter-Frame Attention for Efficient Video Frame Interpolation（cvpr2023）
## 解决问题
- 提取运动信息和外观信息的两种方法：
	- 混合提取：直接将两帧按通道拼接在一起，经过重复的网络模块提取特征。 
		- 缺点1：对特征提取模块的设计和容量有较高的要求
		- 缺点2：因为没有显示的运动信息，无法直接得到任意时刻运动建模所欲的运动信息，这限制了任意时刻插帧的能力
	- 串行提取：首先提取每一帧单独外观信息，再利用两者外观信息提取运动信息。
		- 缺点1：需要针对每一种信息单独设计提取模块，引入额外计算开销
		- 缺点2：无法像混合提取一样只需堆叠相同模块就可以提高性能
		- 缺点3：得到的外观特征没有很好的进行帧间信息交互，而这种信息交互对于生成中间帧至关重要
- **本文提出了一个模块能够同时显式地提取两种信息，并且可以像混合提取那样通过控制模块的个数和容量来控制性能**
	- 优点1：每一帧的外观特征可以相互增强，但不与运动特征混合，以保留详细的静态结构信息
	- 优点2： 所获得的运动特征可以按时间进行缩放，然后作为线索，指导在输入帧之间的任意时刻的帧的生成
	- 优点3：只需要控制模块的复杂性和模块的数量，以平衡整体性能和推理速度
## 解决方案
- 使用CNN提取高分辨率图像的low-level信息。然后使用帧间注意力机制的Transformer块提取低分辨率下运动特征和帧间外观信息。
![帧间注意力](images/ema-vfi1.png)

- 当前帧中的一个区域作为query，而另外相邻帧的所有区域作为key和value。推导出当前区域和另一帧相邻区域的注意力图。该注意力图被用来汇总邻居的外观特征并当前区域的外观特征聚合得到**同一个区域在两帧不同位置的外观信息的聚合特征**，同时该注意力图也被用来对另一帧的相邻区域的位移进行加权得到**当前区域从当前帧到相邻帧的近似运动向量**

![](images/EMA-VFI2.png)

## 缺点
- 尽管混合CNN和Transformer的设计可以减轻计算开销，但它也限制了在的高分辨率外观特征下利用IFA进行运动信息的提取
- 该方法仅限于两个连续帧，无法利用多个连续帧的信息



# AMT: All-Pairs Multi-Field Transforms for Efficient Frame Interpolation（cvpr2023）
## 解决问题
- 现存的插帧预测方法所预测的光流与实际运动不够一致，尤其是运动比较大的时候。而且传统方法难以处理遮挡和运动边界细节。
- 本文提出了一种新的网络架构解决了运动幅度过大和有遮挡的问题

## 解决方案
![](amt1.png)

- correlation encoder : 将输入帧映射到到一对密集特征用来构建双向相关体
- context encoder ： 输出初始插值的中间特征并预测初始化的双边光流$F^1_{t→0}$ 和 $F^1_{t→1}$ 。 同时提取特征金字塔用于更深层次的warping
- 使用预测的双边光流检索相关性来更新流和插值的中间特征
- 从粗双边流中推导多组细粒度流场以便单独对输入帧进行反向扭曲
- 混合使用了CNN和Transform架构



# A Unified Pyramid Recurrent Network for Video Frame Interpolation（cvpr2023）

## 解决问题
- 在传统的光流合成任务中，光流会由一个金字塔网络从粗到细进行估计，但是中间帧只会被合成网络合成一次。这种方式在在低分辨率的视频上有效，但是在***高分辨率***的视频上，这种方法错过了迭代细化过程中插值信息
- 当运动幅度比较大时，插入的中间帧会产生明显的***伪影***
- 现有方法模型架构复杂，很难部署到有限资源的设备上
- 本文针对上述问题提出了一种新颖的**统一金字塔循环网络** 进行双向光流估计和基于forward-warping的帧合成。在光流迭代细化的同时迭代细化中间帧。

## 解决方案
![](upr01.png)
- 首先对给定的两帧输入构建图金字塔。然后对金字塔不同层进行循环估计双向光流和中间帧。该循环结构具体包括一个特征encoder层进行多尺度特征提取，一个双向光流模型用于估计双向光流，一个帧合成模型利用forward-warping合成中间帧。这两个模型共享金字塔层提供的权重。
- 其中，在每个金字塔层，使用CNN对一对输入进行特征提取作为encoder。将最后一个encoder层提取的特征和光流从前一层上采样得到的特征通过双向光流模型处理得到精细化的光流。得到的光流又可以用于输入帧的forward-warp和多尺度CNN特征的更新。最后，帧合成模型结合forward-warp的结果和上一次的中间帧上采样的结果产生中间帧。
![](upr02.png)
- 双向光流模型
![](upr03.png)
- 基于U-Net的帧合成模块
- encoder部分包含三个卷积模块，用于下采样。decoder层也包含三个转置卷积模块用于上采样


作者认为：可以假设在较低分辨率的情况下运动幅度比较小，这样不会产生伪影。如此的话，可以通过低分辨率的结果指导合成高分辨率下的插帧。