动机：解决什么问题
解决方案：创新点，什么架构，什么方法

# Extracting Motion and Appearance via Inter-Frame Attention for Efficient Video Frame Interpolation（cvpr2023）
## 解决问题
- 提取运动信息和外观信息的两种方法：
	- 混合提取：直接将两帧按通道拼接在一起，经过重复的网络模块提取特征。 
		- 缺点1：对特征提取模块的设计和容量有较高的要求
		- 缺点2：因为没有显示的运动信息，无法直接得到任意时刻运动建模所欲的运动信息，这限制了任意时刻插帧的能力
	- 串行提取：首先提取每一帧单独外观信息，再利用两者外观信息提取运动信息。
		- 缺点1：需要针对每一种信息单独设计提取模块，引入额外计算开销
		- 缺点2：无法像混合提取一样只需堆叠相同模块就可以提高性能
		- 缺点3：得到的外观特征没有很好的进行帧间信息交互，而这种信息交互对于生成中间帧至关重要
- **本文提出了一个模块能够同时显式地提取两种信息，并且可以像混合提取那样通过控制模块的个数和容量来控制性能**
	- 优点1：每一帧的外观特征可以相互增强，但不与运动特征混合，以保留详细的静态结构信息
	- 优点2： 所获得的运动特征可以按时间进行缩放，然后作为线索，指导在输入帧之间的任意时刻的帧的生成
	- 优点3：只需要控制模块的复杂性和模块的数量，以平衡整体性能和推理速度
## 解决方案
- 使用CNN提取高分辨率图像的low-level信息。然后使用帧间注意力机制的Transformer块提取低分辨率下运动特征和帧间外观信息。
![帧间注意力](images/ema-vfi1.png)

- 当前帧中的一个区域作为query，而另外相邻帧的所有区域作为key和value。推导出当前区域和另一帧相邻区域的注意力图。该注意力图被用来汇总邻居的外观特征并当前区域的外观特征聚合得到**同一个区域在两帧不同位置的外观信息的聚合特征**，同时该注意力图也被用来对另一帧的相邻区域的位移进行加权得到**当前区域从当前帧到相邻帧的近似运动向量**

![](images/EMA-VFI2.png)

## 缺点
- 尽管混合CNN和Transformer的设计可以减轻计算开销，但它也限制了在的高分辨率外观特征下利用IFA进行运动信息的提取
- 该方法仅限于两个连续帧，无法利用多个连续帧的信息



# AMT: All-Pairs Multi-Field Transforms for Efficient Frame Interpolation
## 解决问题
- 现存的插帧预测方法所预测的光流与实际运动不够一致，尤其是运动比较大的时候。而且传统方法难以处理遮挡和运动边界细节。
- 本文解决了运动幅度过大和有遮挡的问题